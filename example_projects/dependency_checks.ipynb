{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2981 - accuracy: 0.9135\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1413 - accuracy: 0.9589\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1044 - accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0868 - accuracy: 0.9733\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0738 - accuracy: 0.9770\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.07561622560024261, 0.9782999753952026]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow Check\n",
    "import tensorflow as tf\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU')) == 0:\n",
    "    raise Exception('No GPU found')\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [04:51<00:00, 17.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Sum on all episodes 0.0482\n",
      "Final Values Q-Table\n",
      "[[5.98245117e-04 5.99708278e-04 6.90998882e-04 6.04386298e-04]\n",
      " [7.28517330e-04 6.37717377e-04 8.00887342e-04 1.31441879e-03]\n",
      " [9.63490612e-04 9.69022600e-04 8.15789762e-04 4.33504248e-03]\n",
      " [1.15234116e-03 2.79824138e-03 1.07256553e-03 1.26460808e-03]\n",
      " [1.30979818e-03 7.15058859e-04 5.42085808e-03 8.39432140e-04]\n",
      " [1.03801116e-03 1.45305400e-03 6.78626515e-03 1.34232956e-03]\n",
      " [1.23517996e-03 7.37199168e-03 1.21571140e-03 1.14142902e-03]\n",
      " [8.02348433e-03 1.15455789e-03 6.80167432e-04 1.31610222e-03]\n",
      " [6.10772557e-04 7.12047667e-04 7.42308233e-04 6.95782411e-04]\n",
      " [7.14850300e-04 8.28156133e-04 7.26646535e-04 7.29583597e-04]\n",
      " [1.22207178e-03 7.28136623e-04 6.29079345e-04 8.78689669e-04]\n",
      " [8.47091896e-05 7.50478425e-05 2.42470949e-04 3.05878075e-03]\n",
      " [7.87084282e-04 5.82776896e-03 8.21857810e-04 1.36243440e-03]\n",
      " [8.89383735e-04 2.23524224e-03 7.10849803e-03 1.03618911e-03]\n",
      " [1.37427861e-03 1.23408972e-03 9.46385882e-03 1.27773050e-03]\n",
      " [1.32996393e-03 1.43643994e-03 9.84426371e-03 1.29859680e-03]\n",
      " [5.88946283e-04 6.78199702e-04 7.27667764e-04 7.86208467e-04]\n",
      " [5.76785757e-04 5.13467446e-04 7.46461805e-04 8.70093617e-04]\n",
      " [5.46980312e-04 6.50306150e-05 2.48158612e-05 1.19597417e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.34674865e-05 1.40490836e-04 1.82950963e-03 3.48429524e-04]\n",
      " [1.61390115e-04 3.16242507e-04 1.26737140e-04 6.97976488e-03]\n",
      " [7.11173928e-03 1.33327518e-03 7.33987804e-04 9.72040061e-04]\n",
      " [1.06572288e-03 1.20973109e-02 9.41320264e-04 1.30453380e-03]\n",
      " [4.47634203e-04 4.74106321e-04 4.33066471e-04 4.98615702e-04]\n",
      " [4.30679567e-04 3.84433628e-04 3.71571780e-04 3.89664266e-04]\n",
      " [3.21504034e-04 3.78636705e-04 2.28247067e-04 3.45038145e-04]\n",
      " [9.78869906e-08 1.40819797e-04 3.33408218e-04 1.34545667e-04]\n",
      " [3.21709420e-04 4.17926286e-04 8.60915108e-05 2.61977469e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.36736231e-04 2.28648981e-04 7.49060906e-03 2.13949574e-04]\n",
      " [9.78330802e-04 8.50963347e-03 0.00000000e+00 9.75383951e-04]\n",
      " [2.06688837e-04 3.51956036e-04 2.25570284e-04 4.00959113e-04]\n",
      " [3.17676741e-04 1.54465658e-04 3.03037262e-04 4.07183120e-04]\n",
      " [5.43911672e-05 3.38122216e-05 4.84787811e-06 2.87415818e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.59805869e-04 1.18208226e-04 5.42011654e-04 1.39360105e-04]\n",
      " [5.72273617e-04 8.94547141e-04 2.39339078e-04 3.16501772e-06]\n",
      " [0.00000000e+00 2.03887364e-04 2.95625137e-04 3.62202147e-03]\n",
      " [0.00000000e+00 1.15827251e-02 9.02895767e-04 8.34673881e-04]\n",
      " [1.69514077e-04 2.58745710e-06 8.83891065e-05 1.35991898e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.63926932e-06 1.93892547e-04 1.73676012e-04 1.90254328e-05]\n",
      " [7.38355617e-05 1.64917738e-05 2.86432573e-04 5.56939097e-04]\n",
      " [6.46565001e-04 8.09817929e-05 4.00146649e-05 5.09563398e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.37762833e-04 9.77486711e-04 1.75377464e-02 0.00000000e+00]\n",
      " [1.93106097e-04 1.56208855e-04 4.02092666e-05 7.02444468e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.96624948e-05 9.03125426e-05 9.64048664e-05]\n",
      " [1.05345640e-04 6.03835001e-06 6.29187659e-07 6.34511859e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.58454337e-06 4.61158965e-05 5.02783819e-05 4.72691896e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.38873694e-01 2.55351582e-04 0.00000000e+00 0.00000000e+00]\n",
      " [1.85936944e-04 1.51048001e-04 1.19336682e-04 1.02327266e-04]\n",
      " [8.31101882e-05 1.03367459e-04 8.64342152e-05 1.80429232e-05]\n",
      " [9.93292922e-05 3.95510868e-05 1.63782009e-05 2.82258577e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.25017390e-03 2.46002049e-05 9.85606588e-06]\n",
      " [1.28692354e-04 1.17131518e-04 1.25949277e-04 4.04568092e-01]\n",
      " [0.00000000e+00 9.84099835e-01 0.00000000e+00 3.32856972e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gym Check\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# 1. Load Environment and Q-table structure\n",
    "env = gym.make('FrozenLake8x8-v1')\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# env.observation.n, env.action_space.n gives number of states and action in env loaded\n",
    "# 2. Parameters of Q-learning\n",
    "eta = .628\n",
    "gma = .9\n",
    "epis = 5000\n",
    "rev_list = [] # rewards per episode calculate\n",
    "# 3. Q-learning Algorithm\n",
    "for i in tqdm(range(epis)):\n",
    "    # Reset environment\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 99:\n",
    "        env.render()\n",
    "        j+=1\n",
    "        # Choose action from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        #Get new state & reward from environment\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    rev_list.append(rAll)\n",
    "    env.render()\n",
    "print(\"Reward Sum on all episodes \" + str(sum(rev_list)/epis))\n",
    "print(\"Final Values Q-Table\")\n",
    "print(Q)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}